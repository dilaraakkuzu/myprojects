Goodreads Book Recommendation System with PySpark (ALS)
Bu proje, Big Data (BÃ¼yÃ¼k Veri) tekniklerini kullanarak milyonlarca satÄ±rlÄ±k Goodreads veri seti Ã¼zerinde bir kitap Ã¶neri sistemi geliÅŸtirmeyi amaÃ§lar. Proje kapsamÄ±nda PySpark MLlib kÃ¼tÃ¼phanesi ve Alternating Least Squares (ALS) algoritmasÄ± kullanÄ±lmÄ±ÅŸtÄ±r.

ğŸš€ Proje Ã–zeti
Proje, kullanÄ±cÄ±larÄ±n kitaplara verdiÄŸi puanlarÄ± analiz ederek, henÃ¼z okumadÄ±klarÄ± kitaplar iÃ§in tahminler yÃ¼rÃ¼tÃ¼r. Sadece bir Ã¶neri motoru deÄŸil, aynÄ± zamanda bÃ¼yÃ¼k veri ortamÄ±nda bellek yÃ¶netimi ve hiper-parametre optimizasyonu Ã¼zerine kapsamlÄ± bir Ã§alÄ±ÅŸmadÄ±r.

ğŸ› ï¸ KullanÄ±lan Teknolojiler
Dil: Python

Platform: Apache Spark (PySpark)

Makine Ã–ÄŸrenmesi: Collaborative Filtering (ALS AlgoritmasÄ±)

Veri Ä°ÅŸleme: Spark SQL, DataFrames

Veri KaynaÄŸÄ±: Goodreads Interactions & Books Metadata

ğŸ“‹ Ã–ne Ã‡Ä±kan Ã–zellikler
1. BÃ¼yÃ¼k Veri Optimizasyonu
Veri setinin bÃ¼yÃ¼klÃ¼ÄŸÃ¼ (10 Milyondan fazla etkileÅŸim) nedeniyle Spark konfigÃ¼rasyonlarÄ± Ã¶zel olarak ayarlanmÄ±ÅŸtÄ±r:

Driver Memory: 18GB

Executor Memory: 8GB

Partitioning: Veriler user_id Ã¼zerinden 100-200 partition'a bÃ¶lÃ¼nerek shuffle maliyeti dÃ¼ÅŸÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r.

Caching & Checkpointing: EÄŸitim sÃ¼recini hÄ±zlandÄ±rmak ve bellek hatalarÄ±nÄ± Ã¶nlemek iÃ§in veri Ã¶nbelleÄŸe alÄ±nmÄ±ÅŸ ve checkpoint mekanizmasÄ± kullanÄ±lmÄ±ÅŸtÄ±r.

2. Model EÄŸitimi ve Hiper-Parametre Optimizasyonu
En iyi sonucu veren modeli bulmak iÃ§in ÅŸu parametreler Ã¼zerinde Grid Search yapÄ±lmÄ±ÅŸtÄ±r:

Rank (Gizli Ã–zellik SayÄ±sÄ±): [10, 50, 200]

MaxIter (Ä°terasyon SayÄ±sÄ±): [10, 50, 200]

RegParam (Lambda - RegÃ¼larizasyon): [0.01, 0.1]

3. DeÄŸerlendirme Metrikleri
Model baÅŸarÄ±sÄ± RMSE (Root Mean Squared Error) ve MSE Ã¼zerinden Ã¶lÃ§Ã¼lmÃ¼ÅŸtÃ¼r. YapÄ±lan testler sonucunda en dÃ¼ÅŸÃ¼k RMSE deÄŸerine Rank: 200, Iteration: 50/200, Lambda: 0.1 kombinasyonu ile ulaÅŸÄ±lmÄ±ÅŸtÄ±r.

ğŸ” Analiz ve Ã–neriler
Notebook iÃ§erisinde model eÄŸitildikten sonra ÅŸu analizler yapÄ±labilmektedir:

KullanÄ±cÄ± BazlÄ± Tahmin: Belirli bir kullanÄ±cÄ±nÄ±n bir kitaba vereceÄŸi puanÄ±n tahmini.

Benzerlik Analizi: Cosine Similarity kullanÄ±larak bir kitabÄ± en Ã§ok beÄŸenecek potansiyel 10 kullanÄ±cÄ±nÄ±n belirlenmesi.

Metadata Entegrasyonu: goodreads_books.json verisi ile eÅŸleÅŸme yapÄ±larak kitap isimlerinin sonuÃ§lara eklenmesi.

âš™ï¸ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma
Spark Kurulumu: Yerel makinenizde veya bir cluster Ã¼zerinde Apache Spark'Ä±n kurulu olduÄŸundan emin olun.

Veri Seti: Veri setlerini (goodreads_interactions.csv ve goodreads_books.json) notebook ile aynÄ± dizine ekleyin.

KÃ¼tÃ¼phaneler:

Bash
pip install pyspark matplotlib pandas numpy seaborn
Notebook'u Ã‡alÄ±ÅŸtÄ±rÄ±n: als BÄ°G DATA.ipynb dosyasÄ±nÄ± Jupyter Ã¼zerinden baÅŸlatÄ±n.

ğŸ“Š SonuÃ§lar
YapÄ±lan denemeler, gizli Ã¶zellik sayÄ±sÄ± (Rank) arttÄ±kÃ§a modelin veri Ã¼zerindeki karmaÅŸÄ±klÄ±ÄŸÄ± daha iyi kavradÄ±ÄŸÄ±nÄ± ve RMSE deÄŸerinin dÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ gÃ¶stermiÅŸtir. Final modeli als_model_rank200_iter200_lambda0.1 klasÃ¶rÃ¼ne kaydedilmiÅŸtir.

Bu proje, bilgisayar mÃ¼hendisliÄŸi eÄŸitimim kapsamÄ±nda "BÃ¼yÃ¼k Veri Analizi" Ã§alÄ±ÅŸmalarÄ± iÃ§in geliÅŸtirilmiÅŸtir.